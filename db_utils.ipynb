{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\raduh\\miniconda3\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\raduh\\miniconda3\\lib\\site-packages (2.9.9)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\raduh\\miniconda3\\lib\\site-packages (2.0.29)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\raduh\\miniconda3\\lib\\site-packages (from sqlalchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\raduh\\miniconda3\\lib\\site-packages (from sqlalchemy) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml\n",
    "!pip install psycopg2\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credentials():\n",
    "    with open(\"credentials.yaml\", \"r\") as stream:\n",
    "        try:\n",
    "            cred = yaml.safe_load(stream)\n",
    "            return cred\n",
    "        except yaml.YAMLError:\n",
    "            print(yaml.YAMLError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining \"credentials\" function which returns the credentials from the \"credentials.yaml\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDSDatabaseConnector:\n",
    "    \"\"\"\n",
    "    Extracts the remote database to a csv on the local machine.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    cred: dictionary\n",
    "        These are the database credentials obtained from the credentials.yaml file.\n",
    "        They have been converted to a dictionary by a previous function in this file.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    cred: dictionary\n",
    "        Check Parameters section.\n",
    "    engine: engine\n",
    "        Database obtained from the SQLAlchemy method below.\n",
    "    loan_payments: pd.DataFrame\n",
    "        Pandas dataframe obtained from the extract_data method below.\n",
    "\n",
    "    Methods:\n",
    "    ----------\n",
    "    SQLAlchemy(cred)\n",
    "        Imports the RDS database using the credentials. Returns \"engine\".\n",
    "    extract_data(engine)\n",
    "         Converts the database to a pandas data frame. Returns the data frame \"loan_payments\".\n",
    "    save_csv(loan_payments)\n",
    "        Saves the previously obtained data frame to the current directory as a csv file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Class constructor\n",
    "    def __init__(self, cred):\n",
    "        self.cred = cred\n",
    "        \n",
    "    # Methods\n",
    "    def SQLAlchemy(self, cred):\n",
    "        engine = create_engine(f\"postgresql+psycopg2://{self.cred['RDS_USER']}:{self.cred['RDS_PASSWORD']}@{self.cred['RDS_HOST']}:{self.cred['RDS_PORT']}/{self.cred['RDS_DATABASE']}\")\n",
    "        return engine\n",
    "    \n",
    "    def extract_data(self, engine):\n",
    "        sql_query = pd.read_sql_table(\"loan_payments\", engine)\n",
    "        loan_payments = pd.DataFrame(sql_query)\n",
    "        return loan_payments\n",
    "\n",
    "    def save_csv(self, loan_payments):\n",
    "        return loan_payments.to_csv(\"loan_payments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialises a new class \"RDSDatabaseConnector\" which extracts the data from a RDS database to a csv file on the local machine. The class contains three methods.\\\n",
    "\"SQLAlchemy\" - creates an engine which connects to the remote RDS database using the credentials from the YAML file.\\\n",
    "\"extract_data\" - extracts the required data from the database\\\n",
    "\"save_csv\" - saves the previously extracted data as a csv file on the local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df():\n",
    "    with open(\"loan_payments.csv\", \"r\") as payments:\n",
    "        payments_df = pd.read_csv(payments)\n",
    "        return payments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function imports the contents of the previously saved csv file as a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Transforms the data types of the columns in the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "        This is the dataframe to be modifed by the class, this was obatained from the csv file produced by the previous file.\n",
    "        The file was returned as a dataframe by a previous function in this file.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "        Check Parameters section.\n",
    "\n",
    "    Methods:\n",
    "    ----------\n",
    "    change_data_type_category(df)\n",
    "        This function changes the data types of the following columns to category:\n",
    "        Change TERM, GRADE, SUB_GRADE, EMPLOYMENT_LENGTH, HOME_OWNERSHIP, VERIFICATION_STATUS, LOAN_STATUS, PAYMENT_PLAN, PURPOSE, APPLICATION_TYPE to category.\n",
    "    change_data_type_datetime(df)\n",
    "        This function changes the data types of the following columns to datetime64:\n",
    "        Change ISSUE_DATE, EARLIEST_CREDIT_LINE, LAST_PAYMENT_DATE, NEXT_PAYMENT_DATE, LAST_CREDIT_PULL_DATE to datetime64.\n",
    "    \"\"\"\n",
    "\n",
    "    # Class constructor\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    # Methods\n",
    "    def change_data_type_category(self, df):\n",
    "        for column in [\"term\", \"grade\", \"sub_grade\", \"employment_length\", \"home_ownership\", \"verification_status\", \"loan_status\", \"payment_plan\", \"purpose\", \"application_type\"]:\n",
    "            df[column] = df[column].astype(\"category\")\n",
    "        return df\n",
    "    def change_data_type_datetime(self, df):\n",
    "        for column in [\"issue_date\", \"earliest_credit_line\", \"last_payment_date\", \"next_payment_date\", \"last_credit_pull_date\"]:\n",
    "            df[column] = pd.to_datetime(df[column], format = \"%d/%m/%Y\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialises a new class \"DataTransform\" which transforms the data types of the columns in the previously imported pandas data frame. This class contains two methods.\\\n",
    "\"change_data_type_category\" - this changes the datatypes of the identified columns to the category datatype.\\\n",
    "\"change_data_type_datetime\" - this changes the datatypes of columns containing dates/times to datatime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = DataTransform(csv_to_df()).change_data_type_category(csv_to_df())\n",
    "payments_df = DataTransform(payments_df).change_data_type_datetime(payments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above applies the methods in the DataTransform class to the previously created pandas DataFrame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
